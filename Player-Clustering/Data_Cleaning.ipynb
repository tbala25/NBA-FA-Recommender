{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOADING PLAYER DATA (2015-2016, 2016-2017, 2017-2018, 2018-2019 NBA Seasons)\n",
    "\n",
    "train_years = [2016,2017,2018]\n",
    "test_years = [2019]\n",
    "\n",
    "train_per100 = None\n",
    "test_per100 = None\n",
    "train_adv = None\n",
    "test_adv = None\n",
    "\n",
    "for year in train_years:\n",
    "    per100_filepath = '../Data/Player/'+str(year)+'/players_per100.csv'\n",
    "    adv_filepath = '../Data/Player/'+str(year)+'/players_advanced.csv'\n",
    "    \n",
    "    year_per100 = pd.read_csv(per100_filepath)\n",
    "    year_adv = pd.read_csv(adv_filepath)\n",
    "    \n",
    "    #add year to end of team name\n",
    "    year_per100['Player_year'] = year_per100['Player'] + (['/'+ str(year)] * len(year_per100))\n",
    "    #add year column\n",
    "    year_per100['Year'] = year\n",
    "\n",
    "    #add year to end of team name\n",
    "    year_adv['Player_year'] = year_adv['Player'] + (['/'+ str(year)] * len(year_adv))\n",
    "    \n",
    "    #ADDING ALL_STAR_CALIBER field\n",
    "    year_adv['All-Star_caliber'] = 0\n",
    "    year_adv.loc[year_adv.sort_values(by='WS', ascending = False).iloc[:45,:].index,'All-Star_caliber'] = 1\n",
    "    \n",
    "    if train_per100 is None:\n",
    "        train_per100 = year_per100\n",
    "    else:\n",
    "        train_per100 = train_per100.append(year_per100, ignore_index = True)\n",
    "        \n",
    "    if train_adv is None:\n",
    "        train_adv = year_adv\n",
    "    else:\n",
    "        train_adv = train_adv.append(year_adv, ignore_index = True)\n",
    "        \n",
    "\n",
    "        \n",
    "for year in test_years:\n",
    "    per100_filepath = '../Data/Player/'+str(year)+'/players_per100.csv'\n",
    "    adv_filepath = '../Data/Player/'+str(year)+'/players_advanced.csv'\n",
    "    \n",
    "    year_per100 = pd.read_csv(per100_filepath)\n",
    "    year_adv = pd.read_csv(adv_filepath)\n",
    "    \n",
    "    #add year to end of team name\n",
    "    year_per100['Player_year'] = year_per100['Player'] + (['/'+ str(year)] * len(year_per100))\n",
    "    #add year column\n",
    "    year_per100['Year'] = year\n",
    "    \n",
    "    #add year to end of team name\n",
    "    year_adv['Player_year'] = year_adv['Player'] + (['/'+ str(year)] * len(year_adv))\n",
    "    \n",
    "    #ADDING ALL_STAR_CALIBER field\n",
    "    year_adv['All-Star_caliber'] = 0\n",
    "    year_adv.loc[year_adv.sort_values(by='WS', ascending = False).iloc[:45,:].index,'All-Star_caliber'] = 1\n",
    "    \n",
    "    if test_per100 is None:\n",
    "        test_per100 = year_per100\n",
    "    else:\n",
    "        test_per100 = test_per100.append(year_per100, ignore_index = True)\n",
    "        \n",
    "    if test_adv is None:\n",
    "        test_adv = year_adv\n",
    "    else:\n",
    "        test_adv = train_adv.append(year_adv, ignore_index = True) \n",
    "\n",
    "# #drop unnamed and index columns\n",
    "train_adv = train_adv.drop(['Rk','Unnamed: 19', 'Unnamed: 24'], axis=1)\n",
    "train_per100 = train_per100.drop(['Rk','Unnamed: 29'], axis=1)\n",
    "test_adv = test_adv.drop(['Rk','Unnamed: 19', 'Unnamed: 24'], axis=1)\n",
    "test_per100 = test_per100.drop(['Rk','Unnamed: 29'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FIX POSITIONS\n",
    "##TAKEOUT DUPLICATE ROWS FROM PLAYERS THAT CHANGED TEAMS MID-SEASON\n",
    "\n",
    "##########TRAIN PER100###########\n",
    "\n",
    "players_w_tot = train_per100.loc[train_per100.loc[:,'Tm'] == 'TOT','Player']\n",
    "players_multi  = set(players_w_tot)\n",
    "\n",
    "for i in range(len(train_per100)):\n",
    "    #FIX POSITION\n",
    "    #if positions has '-' take first position\n",
    "    if '-' in train_per100.loc[i,'Pos']:\n",
    "        #print(p1.loc[i,'Pos_x'])\n",
    "        train_per100.loc[i,'Pos'] =  train_per100.loc[i,'Pos'].split('-')[0]\n",
    "\n",
    "    #ONLY KEEP TOT rows\n",
    "    if train_per100.loc[i, 'Player'] in players_multi:\n",
    "        #drop all rows where team is not TOT\n",
    "        if train_per100.loc[i, 'Tm'] != 'TOT':\n",
    "            #drop a row\n",
    "            train_per100 = train_per100.drop(i)\n",
    "\n",
    "##########TEST PER100###########          \n",
    "            \n",
    "players_w_tot = test_per100.loc[test_per100.loc[:,'Tm'] == 'TOT','Player']\n",
    "players_multi  = set(players_w_tot)\n",
    "\n",
    "for i in range(len(test_per100)):\n",
    "    #FIX POSITION\n",
    "    #if positions has '-' take first position\n",
    "    if '-' in test_per100.loc[i,'Pos']:\n",
    "        #print(p1.loc[i,'Pos_x'])\n",
    "        test_per100.loc[i,'Pos'] =  test_per100.loc[i,'Pos'].split('-')[0]\n",
    "\n",
    "    #ONLY KEEP TOT rows\n",
    "    if test_per100.loc[i, 'Player'] in players_multi:\n",
    "        #drop all rows where team is not TOT\n",
    "        if test_per100.loc[i, 'Tm'] != 'TOT':\n",
    "            #drop a row\n",
    "            test_per100 = test_per100.drop(i)\n",
    "\n",
    "##########TRAIN ADV###########\n",
    "\n",
    "players_w_tot = train_adv.loc[train_adv.loc[:,'Tm'] == 'TOT','Player']\n",
    "players_multi  = set(players_w_tot)\n",
    "\n",
    "for i in range(len(train_adv)):\n",
    "    #FIX POSITION\n",
    "    #if positions has '-' take first position\n",
    "    if '-' in train_adv.loc[i,'Pos']:\n",
    "        train_adv.loc[i,'Pos'] =  train_adv.loc[i,'Pos'].split('-')[0]\n",
    "\n",
    "    #ONLY KEEP TOT rows\n",
    "    if train_adv.loc[i, 'Player'] in players_multi:\n",
    "        #drop all rows where team is not TOT\n",
    "        if train_adv.loc[i, 'Tm'] != 'TOT':\n",
    "            #drop a row\n",
    "            train_adv = train_adv.drop(i)\n",
    "\n",
    "##########TEST ADV###########\n",
    "\n",
    "players_w_tot = test_adv.loc[test_adv.loc[:,'Tm'] == 'TOT','Player']\n",
    "players_multi  = set(players_w_tot)\n",
    "\n",
    "for i in range(len(test_adv)):\n",
    "    #FIX POSITION\n",
    "    #if positions has '-' take first position\n",
    "    if '-' in test_adv.loc[i,'Pos']:\n",
    "        test_adv.loc[i,'Pos'] =  test_adv.loc[i,'Pos'].split('-')[0]\n",
    "\n",
    "    #ONLY KEEP TOT rows\n",
    "    if test_adv.loc[i, 'Player'] in players_multi:\n",
    "        #drop all rows where team is not TOT\n",
    "        if test_adv.loc[i, 'Tm'] != 'TOT':\n",
    "            #drop a row\n",
    "            test_adv = test_adv.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MERGING TABLES\n",
    "\n",
    "train = train_per100.merge(train_adv, left_on = 'Player_year', right_on = 'Player_year', how = 'left')\n",
    "test = test_per100.merge(test_adv, left_on = 'Player_year', right_on = 'Player_year', how = 'left')\n",
    "\n",
    "#Drop duplicate columns from merge\n",
    "train = train.drop(['Player_y','Pos_y','Age_y','Tm_y','G_y','MP_y'], axis = 1)\n",
    "test = test.drop(['Player_y','Pos_y','Age_y','Tm_y','G_y','MP_y'], axis = 1)\n",
    "\n",
    "#Fill NA values with 0\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add full team/year column\n",
    "\n",
    "# ADD TEAM ABBREVIATIONS\n",
    "\n",
    "tm_abrv = np.array([['ATL','Atlanta Hawks'],\n",
    "['BKN','Brooklyn Nets'],\n",
    "['BRK','Brooklyn Nets'],\n",
    "['BOS','Boston Celtics'],\n",
    "['CHA','Charlotte Hornets'],\n",
    "['CHO','Charlotte Hornets'],\n",
    "['CHI','Chicago Bulls'],\n",
    "['CLE','Cleveland Cavaliers'],\n",
    "['DAL','Dallas Mavericks'],\n",
    "['DEN','Denver Nuggets'],\n",
    "['DET','Detroit Pistons'],\n",
    "['GSW','Golden State Warriors'],\n",
    "['HOU','Houston Rockets'],\n",
    "['IND','Indiana Pacers'],\n",
    "['LAC','Los Angeles Clippers'],\n",
    "['LAL','Los Angeles Lakers'],\n",
    "['MEM','Memphis Grizzlies'],\n",
    "['MIA','Miami Heat'],\n",
    "['MIL','Milwaukee Bucks'],\n",
    "['MIN','Minnesota Timberwolves'],\n",
    "['NOP','New Orleans Pelicans'],\n",
    "['NYK','New York Knicks'],\n",
    "['OKC','Oklahoma City Thunder'],\n",
    "['ORL','Orlando Magic'],\n",
    "['PHI','Philadelphia 76ers'],\n",
    "['PHX','Phoenix Suns'],\n",
    "['PHO','Phoenix Suns'],\n",
    "['POR','Portland Trail Blazers'],\n",
    "['SAC','Sacramento Kings'],\n",
    "['SAS','San Antonio Spurs'],\n",
    "['TOR','Toronto Raptors'],\n",
    "['UTA','Utah Jazz'],\n",
    "['WAS','Washington Wizards']])\n",
    "\n",
    "tm_abrv = pd.DataFrame(tm_abrv, columns = ['Abrv', 'Team_full'])\n",
    "\n",
    "train_1 = train.merge(tm_abrv, left_on = 'Tm_x', right_on = 'Abrv')\n",
    "test_1 = test.merge(tm_abrv, left_on = 'Tm_x', right_on = 'Abrv')\n",
    "\n",
    "train_1['Team_full'] = train_1.apply(lambda row: row.Team_full + '/' + str(row.Year), axis=1)\n",
    "test_1['Team_full'] = test_1.apply(lambda row: row.Team_full + '/' + str(row.Year), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1.to_csv('train_players_cleaned.csv')\n",
    "test_1.to_csv('test_players_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATL',\n",
       " 'BOS',\n",
       " 'BRK',\n",
       " 'CHI',\n",
       " 'CHO',\n",
       " 'CLE',\n",
       " 'DAL',\n",
       " 'DEN',\n",
       " 'DET',\n",
       " 'GSW',\n",
       " 'HOU',\n",
       " 'IND',\n",
       " 'LAC',\n",
       " 'LAL',\n",
       " 'MEM',\n",
       " 'MIA',\n",
       " 'MIL',\n",
       " 'MIN',\n",
       " 'NOP',\n",
       " 'NYK',\n",
       " 'OKC',\n",
       " 'ORL',\n",
       " 'PHI',\n",
       " 'PHO',\n",
       " 'POR',\n",
       " 'SAC',\n",
       " 'SAS',\n",
       " 'TOR',\n",
       " 'UTA',\n",
       " 'WAS'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_1['Tm_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
